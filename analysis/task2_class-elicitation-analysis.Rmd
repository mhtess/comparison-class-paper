---
title: "class-elicitation-analysis"
author: "MH Tessler"
date: "6/11/2020"
output: html_document
---

```{r}
library(tidyverse)
library(tidyboot)
library(ggplot2)
library(brms)
library(knitr)
library(ggthemes)
theme_set(theme_few())
```

``` {r}
# read data

# whatever data needs to go into the regression model
# uncomment below for automatically classified data only
# data <- read_csv("../../data/class-elicitation-prereg-final/auto-classified-data-w-freqs-final.csv")
# uncomment below for full classified data
# data <- read_csv("../data/class-elicitation-prereg-final/full-classified-data-w-hand-class.csv")

# automatically classified data, for viz
# df.auto <- read_csv("../../data/class-elicitation-prereg-final/auto-classified-data-full-w-freqs-final.csv")

df.auto <- read_csv("../data/task2_comparison-class-inference/class-inference_preprocessed_noInvalid_noRefFail.csv")

# df.auto %>% 
#   mutate(specific = as.numeric(specific)) %>%
#   write_csv(., 
#           path =  "../../data/class-elicitation-prereg-final/class-elicitation_auto-classified_frequencies.csv")
```


## Descriptive stats

### Corrections

```{r}
df.auto %>%
  select(starts_with("corrected_")) %>%
  gather(key, val) %>%
  group_by(key) %>%
  summarize(total = sum(val),
            n = n(),
            prop = 100*total / n) -> df_corrections


write_csv(df_corrections, "../../comparison-class/writing/paper/csv_data_4_tex/correction_counts.csv")

```


### Exact matches

How many responses match the predefined superordinate category?
How many match the subordinate category?
How many neither?

```{r}

df.auto %>%
  group_by(specific, matchingSuper) %>%
  count() %>%
  ungroup() %>%
  mutate(
    type = paste(ifelse(specific == 1, "Subordinate", "notSubordinate"), 
                 "_", 
                 ifelse(matchingSuper, "Superordinate", "notSuperordinate"), 
                 sep = ""
                 ),
    total_n = sum(n),
    prop = 100*n / total_n
    ) -> df_mentionSpecificCategoryCounts

write_csv(df_mentionSpecificCategoryCounts, "../../comparison-class/writing/paper/csv_data_4_tex/mention_category_counts.csv")

matching.responses <- with(df.auto, table(specific, matchingSuper))

prop.table(matching.responses) %>% 
  kable()

```

```{r}
d.tidy.auto.match <- df.auto %>%
  filter(matchingSuper | specific)

n.automatic.responses <- d.tidy.auto.match %>%
  ungroup() %>%
  count() %>%
  pull(n)

n.automatic.responses
n.automatic.responses / length(df.auto$response)

# write_csv(d.tidy.auto.match, "../../data/class-elicitation-prereg-final/class-elicitation_auto-classified_mexact-match_frequencies.csv")
```


# Visualisations

```{r}
count_summary_fn <- function(x) x %>% 
  summarize(n = n()) %>%
  mutate(stat = n / sum(n))

mean_ci_funs <- list("ci_lower" = ci_lower, "mean" = mean, "ci_upper" = ci_upper)

df %>%
  group_by(premise_1, premise_2, conclusion) %>%
  tidyboot(summary_function = count_summary_fn,
           statistics_functions = function(x) x %>%
             summarise(across(stat, mean_ci_funs, .names = "{.fn}"))) %>%
  ungroup() %>% 
  rowwise() %>%
  mutate(conclusion_quantifier = str_split(conclusion, ";")[[1]][1]) -> df.summ
```


```{r}
d.tidy.3way.bs <- df.auto %>%
  select(np_expectations, adj_polarity, specific, matchingSuper) %>%
  mutate(
    response_type = case_when(
      specific == 1 ~ "subordinate",
      matchingSuper ~ "modal superordinate", 
      TRUE ~ "other superordinate"
    )
  ) %>%
  group_by(np_expectations, adj_polarity, response_type) %>%
  tidyboot(summary_function = count_summary_fn,
           statistics_functions = function(x) x %>%
             summarise(across(stat, mean_ci_funs, .names = "{.fn}"))) 




d.tidy.3way.bs %>%
  ungroup () %>%
  mutate(
    np_expectations = factor(np_expectations, levels = c("low", "medium", "high")),
    response_type = factor(response_type, levels = c("subordinate", "modal superordinate", "other superordinate"))
  ) %>%
  ggplot(
    .,
    aes(
      x = np_expectations, y = mean,
      ymin = ci_lower, ymax = ci_upper, fill = response_type
    )
  ) +
  geom_col(
    position = position_dodge(0.8), width = 0.8, alpha = 0.7, color = "black", size = 1
  ) +
  geom_linerange(
    position = position_dodge(0.8), color = "black", size = 1.5
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line = element_line(colour = "black")
  ) +
  guides(fill = guide_legend(title = "Response Type", reverse = F)) +
  # theme_black()+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1)) +
  ylab("Proportion of Responses") +
  xlab("General Expectations of Subordinate Category")+
  facet_wrap(~adj_polarity)


ggsave(
  filename = "../../comparison-class/writing/paper/figs/3way_bars_cc_finalExpt.pdf",
  width = 7, height = 3.2
)
```


```{r}
d.tidy.phrase.specificMarking.bs <- df.auto %>%
  group_by(np_expectations, adj_polarity) %>%
  tidyboot_mean(column = specific)

d.tidy.phrase.specificMarking.bs.item <- df.auto %>%
  group_by(stim_id, degree, superordinate_pl, np_expectations, 
           subordinate_sg, adj_polarity) %>%
  tidyboot_mean(column = specific)

d.tidy.phrase.specificMarking.bs %>%
  ungroup() %>%
  mutate(
    np_expectations = gsub('\"', "", np_expectations),
    adj_polarity = gsub('\"', "", adj_polarity),
    np_expectations = factor(np_expectations,
      levels = c("low", "medium", "high")
    )
  ) -> d.tidy.phrase.specificMarking.bs

d.tidy.phrase.specificMarking.bs.item %>%
  ungroup() %>%
  mutate(unique_id = paste(stim_id, np_expectations, sep = "-")) %>%
  mutate(np_expectations = factor(np_expectations,
    levels = c("low", "medium", "high")
  )) -> d.tidy.phrase.specificMarking.bs.item

save(d.tidy.phrase.specificMarking.bs, 
     d.tidy.phrase.specificMarking.bs.item, 
     file = "../../writing/paper/cached_results/class-elicitation-bs-byItem-fullSet.RData")
#load(file = "../../writing/paper/cached_results/class-elicitation-bs-byItem-fullSet.RData") # d.tidy.phrase.specificMarking.bs, d.tidy.phrase.specificMarking.bs.item, file =

set.seed(2020)

d.tidy.phrase.specificMarking.bs.item %>%
  left_join(
    .,
    data.frame(
      unique_id = unique(d.tidy.phrase.specificMarking.bs.item$unique_id),
      jitterVal = runif(270, min = -0.07, max = 0.07)
    )
  ) %>%
  mutate(
    jitterVal = jitterVal + ifelse(adj_polarity == "positive", 0.2, -0.2)
  ) %>%
  ggplot(
    .,
    aes(
      x = as.numeric(np_expectations) + jitterVal, y = mean,
      ymin = ci_lower, ymax = ci_upper, fill = adj_polarity
    )
  ) +
  geom_col(
    data = d.tidy.phrase.specificMarking.bs,
    aes(
      x = np_expectations, y = mean,
      ymin = ci_lower, ymax = ci_upper, fill = adj_polarity
    ),
    position = position_dodge(0.8), width = 0.8, alpha = 0.6, color = "black", size = 1
  ) +
  geom_point( # position = position_dodge(0.8),
    # position = position_jitterdodge(jitter.width = 0.2, jitter.height = 0),
    # data = d.tidy.phrase.specificMarking.bs.item,
    # aes( y = mean, fill = adj_polarity, x = np_expectations),
    shape = 21, alpha = 0.8
  ) +
  geom_path(aes(group = unique_id),
    # position = position_dodge(0.8),
    alpha = 0.15
  ) +
  geom_linerange(
    data = d.tidy.phrase.specificMarking.bs,
    aes(
      x = np_expectations, y = mean,
      ymin = ci_lower, ymax = ci_upper
    ),
    position = position_dodge(0.8), color = "black", size = 1.5
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme( # axis.text.x = element_text(angle = 45, hjust = 1.0, vjust = 1),
    # axis.title.x = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line = element_line(colour = "black")
  ) +
  guides(fill = guide_legend(title = "Adjective polarity", reverse = T)) +
  # theme_black()+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1)) +
  ylab("Proportion of Subordinate Comparison Class Inferences") +
  xlab("General Expectations of Subordinate Category")

# ggsave(
#   filename = "../../writing/paper/figs/bars_cc_finalExpt_prereg_bars_syncDodge.pdf",
#   width = 6, height = 4
# )

# save(d.tidy.phrase.specificMarking.bs.item, file = "d_comparisonClass_specific_bs_item.RData")
```

```{r}
# look at data matched automatically by-item
d.confident.phrase.specificMarking.bs.item <- auto_data %>%
  # mutate() %>%
  group_by(stim_id, degree, superordinate, np_expectations, np, adj_polarity) %>%
  mean(specific)

d.tidy.phrase.specificMarking.bs %>%
  ungroup() %>%
  mutate(
    np_expectations = gsub('\"', "", np_expectations),
    adj_polarity = gsub('\"', "", adj_polarity),
    np_expectations = factor(np_expectations,
      levels = c("low", "medium", "high")
    )
  ) %>%
  ggplot(
    .,
    aes(
      x = np_expectations, y = mean,
      ymin = ci_lower, ymax = ci_upper, fill = adj_polarity
    )
  ) +
  geom_col(position = position_dodge(0.8), width = 0.8, alpha = 0.6, color = "black", size = 1) +
  geom_point(
    position = position_jitterdodge(jitter.width = 0.2, jitter.height = 0),
    data = d.tidy.phrase.specificMarking.bs.item,
    aes(y = mean, fill = adj_polarity, x = np_expectations),
    shape = 21, alpha = 0.8
  ) +
  geom_linerange(position = position_dodge(0.8), color = "black", size = 1) +
  scale_fill_brewer(palette = "Set3") +
  theme( # axis.text.x = element_text(angle = 45, hjust = 1.0, vjust = 1),
    # axis.title.x = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line = element_line(colour = "black")
  ) +
  # theme_black()+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1)) +
  ylab("Proportion paraphrases that contain Specific NP") +
  xlab("Subordinate Category General Expectations")

# ggsave(filename = "../writing/paper/figs/bars_cc_finalExpt_prereg_bars.pdf",
#        width = 6, height = 4)
```

## By-item plots

```{r figIndivItems}
select.items <- d.tidy.phrase.specificMarking.bs.item %>%
  select(degree, np, stim_id, superordinate, np_expectations, adj_polarity, mean) %>%
  rowwise() %>%
  mutate(degree = first(strsplit(degree, "_")[[1]])) %>%
  spread(adj_polarity, mean) %>%
  mutate(delta = positive - negative) %>%
  ungroup() %>%
  group_by(degree, stim_id, superordinate) %>%
  summarize(mean_delta = mean(abs(delta)))

select.items %>%
  group_by(degree) %>%
  mutate(
    max_val = max(mean_delta),
    min_val = min(mean_delta)
  ) %>%
  ungroup() %>%
  filter(mean_delta == max_val | mean_delta == min_val) %>%
  pull(stim_id) -> select.item.ids

# swap tall/short people with tall/short flowers
select.item.ids <- c(select.item.ids[select.item.ids != 17], 18)

# 17 for 18

# select.items[with(select.items, order(mean_delta)), ][seq(1, 90, 3), ]

d.tidy.phrase.specificMarking.bs.item %>%
  filter(stim_id %in% select.item.ids) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(degree = first(strsplit(degree, "_")[[1]])) %>%
  ungroup() %>%
  mutate(
    np_expectations = gsub('\"', "", np_expectations),
    adj_polarity = gsub('\"', "", adj_polarity),
    np_expectations = factor(np_expectations,
      levels = c("low", "medium", "high")
    ),
    np = fct_reorder(np, as.numeric(np_expectations)),
    item_set = paste(degree, " - ", superordinate, "-", stim_id, sep = ""),
    item_name = paste(superordinate, " (", degree, ")", sep = ""),
    item_name = factor(item_name),
    item_set = factor(item_set),
    item_name = fct_reorder(item_name, as.numeric(item_set))
  ) %>%
  ggplot(
    .,
    aes(x = np, y = mean, fill = adj_polarity)
  ) +
  geom_col(position = position_dodge(0.8), width = 0.8, alpha = 0.7, color = "black") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),
    position = position_dodge(0.8), color = "black"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 0.8, vjust = 0.85),
    # axis.title.x = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line = element_line(colour = "black"),
    legend.position = "bottom"
  ) +
  facet_wrap(~item_name, scales = "free", nrow = 4) +
  # theme_black()+
  scale_y_continuous(limits = c(-0.02, 1.02), breaks = c(0, 0.5, 1)) +
  guides(fill = guide_legend(title = "Adjective polarity", reverse = T)) +
  ylab("Proportion paraphrases that contain Specific NP") +
  xlab("Specific Category") #-> bars_cc_finalExpt_prereg_confident_byItem

# ggsave("../analysis/figs/bars_cc_finalExpt_pilot_byItem.png",
#        width = 9, height = 9)
ggsave(
  filename = "../writing/paper/figs/bars_cc_finalExpt_prereg_byItem.pdf",
  width = 15, height = 10
)
```

# Regression modeling

## BRM model

### run model

```{r}
#d.tidy.clean.responses.fac <- df.auto %>%
d.tidy.clean.responses.fac <- d.tidy.auto.match %>%
  mutate(
    adj_polarity = factor(adj_polarity,
      levels = c("negative", "positive")
    ),
    np_expectations = factor(np_expectations,
      levels = c("medium", "low", "high")
    )
  )

d.tidy.clean.responses.fac$stim_id <- as.factor(d.tidy.clean.responses.fac$stim_id)
d.tidy.clean.responses.fac$workerid <- as.factor(d.tidy.clean.responses.fac$workerid)

contrasts(d.tidy.clean.responses.fac$adj_polarity) <- c(-1 / 2, 1 / 2)

rs.glm.brm <- brm(
  formula = specific ~ np_expectations * adj_polarity +
    (1 + np_expectations * adj_polarity | workerid) +
    (1 + np_expectations * adj_polarity | stim_id),
  family = bernoulli(), chains = 4, cores = 4, 
  iter = 10000,
  seed = 2020,
  data = d.tidy.clean.responses.fac,
  file = "rs_brm_glm_exact-match_4chain_10k_2"
)

contrasts(d.tidy.clean.responses.fac$adj_polarity)
contrasts(d.tidy.clean.responses.fac$np_expectations)

rs.glm.brm.summary <- summary(rs.glm.brm)

rs.glm.brm.summary
```

### compute marginal posteriors

```{r}
rs.glm.brm.betas.samples <- brms::posterior_samples(rs.glm.brm, add_chain = T) %>% 
  select(starts_with("b_")) %>%
  rename(
    intercept = b_Intercept,
    nplow = b_np_expectationslow,
    nphigh = b_np_expectationshigh,
    adjpol = b_adj_polarity1,
    adjpol_nplow = `b_np_expectationslow:adj_polarity1`,
    adjpol_nphigh = `b_np_expectationshigh:adj_polarity1`
  ) %>%
  mutate(
    highneg_highpos = -adjpol - adjpol_nphigh,
    lowneg_lowpos = -adjpol - adjpol_nplow,
    lowneg_highneg = nplow - nphigh - 
      0.5 * adjpol_nplow + 0.5 * adjpol_nphigh,
    lowpos_highpos = nplow - nphigh + 
      0.5 * adjpol_nplow - 0.5 * adjpol_nphigh,
    lowneg_highpos = -adjpol + nplow - nphigh - 
      0.5 * adjpol_nplow - 0.5 * adjpol_nphigh,
    lowpos_highneg = adjpol + nplow - nphigh + 
      0.5 * adjpol_nplow + 0.5 * adjpol_nphigh
  ) 

write_csv(rs.glm.brm.betas.samples,
          path = "../../writing/paper/cached_results/rs_brm_glm_exact-match_4chain_10k_samples2.csv")



rs.glm.brm.betas.samples %>%
  gather(key, val) %>% 
  group_by(key) %>%
  summarize(
    'l95' = quantile(val, probs = c(0.025, 0.975))[[1]],
    'mean'  = mean(val),
    'u95' = quantile(val, probs = c(0.025, 0.975))[[2]],
    prob_gt_0 = mean(val > 0)*100,
    prob_lt_0 = mean(val < 0)*100
  ) -> rs.glm.brm.full.contrasts

write_csv(rs.glm.brm.full.contrasts,
          path = "../../writing/paper/csv_data_4_tex/expt_brm_exact-match_contrasts_10k_2.csv")
```


# Universally consistent responses

```{r check ceiling/floor responses}
# check the matched items where the mean of responses is 1 or 0
# df.auto %>%
d.tidy.auto.match %>%
  group_by(stim_id, np_expectations, adj_polarity) %>%
  mutate(meanResp = mean(specific)) %>%
  filter((meanResp == 1) | (meanResp == 0)) %>%
  distinct(
    stim_id, np_expectations,
    keyword, adj_polarity, adj,
    response_lemma, # showing response_lemma will show the individual (lemmatized) responses that were all categorized as either sub or super
    meanResp
  ) -> d.match.ceiling
  
d.match.ceiling %>%
  distinct(stim_id, np_expectations, adj_polarity, meanResp) %>%
  group_by(meanResp) %>%
  count()

d.match.ceiling %>%
  ungroup() %>%
  distinct(
    stim_id, np_expectations,  
    keyword, adj,
    meanResp
  ) %>%
  #sample_n(20) %>%
  kable()
  #View()

d.match.ceiling %>%
  ungroup() %>%
  filter(meanResp == 1) %>%
  distinct(
    stim_id, np_expectations,  
    keyword, adj_polarity,
    meanResp
  ) %>%
  group_by(np_expectations, adj_polarity) %>%
  count() %>%
  ungroup() %>%
  mutate(np_expectations = factor(np_expectations, levels = c("low", "medium", "high"))) %>%
  rename(adjpol = adj_polarity) %>%
  spread(np_expectations, n) %>% 
  mutate(medium = ifelse(is.na(medium), 0, medium)) %>%
  #kable()
  write_csv(., "../../writing/paper/csv_data_4_tex/itemCounts_ceil_floor_fulldata.csv")
```




## (depracated?) Simulate data to get contrast coding right

```{r}
simulated.data <- bind_rows(
  data.frame(
    np = "mid",
    adj = "short",
    x = rnorm(n = 20, mean = 1, sd = 0.5)
  ),
  data.frame(
    np = "mid",
    adj = "tall",
    x = rnorm(n = 20, mean = 1, sd = 0.5)
  ),
  data.frame(
    np = "low",
    adj = "short",
    x = rnorm(n = 20, mean = 0.5, sd = 0.5)
  ),
  data.frame(
    np = "low",
    adj = "tall",
    x = rnorm(n = 20, mean = 1.5, sd = 0.5)
  ),
  data.frame(
    np = "high",
    adj = "short",
    x = rnorm(n = 20, mean = 1.5, sd = 0.5)
  ),
  data.frame(
    np = "high",
    adj = "tall",
    x = rnorm(n = 20, mean = 0.5, sd = 0.5)
  )
) %>%
  mutate(
    np = factor(np, levels = c("mid", "low", "high")),
    adj = factor(adj, levels = c("short", "tall"))
  )

simulated.data.means <- simulated.data %>%
  group_by(np, adj) %>%
  summarize(m = mean(x))

simulated.data.means %>%
  ggplot(., aes(x = np, y = m, fill = adj)) +
  geom_col(position = position_dodge())


contrasts(simulated.data$adj) <- c(-0.5, 0.5)

contrasts(simulated.data$np)

lm.sim <- lm(x ~ np * adj, data = simulated.data)

lm.sim.summ <- summary(lm.sim)

sim.int <- lm.sim.summ$coefficients[["(Intercept)", "Estimate"]]
sim.beta_adj <- lm.sim.summ$coefficients[["adj1", "Estimate"]]
sim.beta_npLow <- lm.sim.summ$coefficients[["nplow", "Estimate"]]
sim.beta_npHigh <- lm.sim.summ$coefficients[["nphigh", "Estimate"]]
sim.beta_npLow_adj <- lm.sim.summ$coefficients[["nplow:adj1", "Estimate"]]
sim.beta_npHigh_adj <- lm.sim.summ$coefficients[["nphigh:adj1", "Estimate"]]

print(
  paste(
    "actual mean of MID tall",
    simulated.data.means %>% filter(np == "mid", adj == "tall") %>% pull(m),
    "model prediction",
    sim.int + 0.5 * sim.beta_adj
  )
)

print(
  paste(
    "actual mean of MID short",
    simulated.data.means %>% filter(np == "mid", adj == "short") %>% pull(m),
    "model prediction",
    sim.int - 0.5 * sim.beta_adj
  )
)

print(
  paste(
    "actual mean of HIGH tall",
    simulated.data.means %>% filter(np == "high", adj == "tall") %>% pull(m),
    "model prediction",
    sim.int + 0.5 * sim.beta_adj + sim.beta_npHigh + 0.5 * sim.beta_npHigh_adj
  )
)

print(
  paste(
    "actual mean of HIGH short",
    simulated.data.means %>% filter(np == "high", adj == "short") %>% pull(m),
    "model prediction",
    sim.int - 0.5 * sim.beta_adj + sim.beta_npHigh - 0.5 * sim.beta_npHigh_adj
  )
)

print(
  paste(
    "actual mean of LOW tall",
    simulated.data.means %>% filter(np == "low", adj == "tall") %>% pull(m),
    "model prediction",
    sim.int + 0.5 * sim.beta_adj + sim.beta_npLow + 0.5 * sim.beta_npLow_adj
  )
)

print(
  paste(
    "actual mean of LOW short",
    simulated.data.means %>% filter(np == "low", adj == "short") %>% pull(m),
    "model prediction",
    sim.int - 0.5 * sim.beta_adj + sim.beta_npLow - 0.5 * sim.beta_npLow_adj
  )
)
```

